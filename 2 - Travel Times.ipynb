{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Transit Travel Times with r5py\n",
    "\n",
    "This notebook is modified based on Acess presentation by Dr Willem to calculate access to opportunities using r5py.\n",
    "\n",
    "This is a generally computationally intensive process, and has been the main technical hurdle to overcome in this process.\n",
    "\n",
    "In this workbook, we are going to generate transit travel times using a relativley new Python library `r5py`. R5py is designed to allow Python users to access the open-source R5 engine, a powerful engine that is the spiritual successort to OpenTripPlanner. You can ready more about r5py via [their documentation](https://r5py.readthedocs.io), or check out [R5's own github page](https://github.com/conveyal/r5).\n",
    "In this workbook we are going to generate transit travel time using the Python library r5py.\n",
    "\n",
    "In our example analysis, we want to answer two questions:\n",
    "- How is the access to hospitals distributed across different populations?\n",
    "- How is the access to child care spaces distributed across different populations?\n",
    "- How does peak-period and evening service change this access for various populations?\n",
    "\n",
    "For this we need to generate *two* travel time matrices. One for a peak period (7-9am) and for an evening period (9-11pm).\n",
    "\n",
    "The beauty of the R5 engine is that it allows us to measure a median peak-period value very easily. To do this, we start our analysis at the beginning of our specified time period and set the duration of the analysis.\n",
    "\n",
    "Let's start by loading the appropriate data and setting some key settings for R5py. One little quirk we are going to need is that R5py requires our origin/destination points to be named `id`, not anything else like `dauid`. We'll make that change now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1675\n",
      "368\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shapely\n",
    "import numpy as np\n",
    "#os.environ['GDAL_DATA'] = os.path.join(f'{os.sep}'.join(sys.executable.split(os.sep)[:-1]), 'Library', 'share', 'gdal')\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# This sets the amount of memory we are using for R5py calcualtions\n",
    "#sys.argv.append([\"--max-memory\", \"8G\"])\n",
    "\n",
    "#da_centroids = gpd.read_file(\"data/UnAdj_100m_2020.geojson\").rename(columns={\"pointid\":\"id\"})#\n",
    "#dest_po = gpd.read_file(\"data/guadalajara_greenspace_perimeterpoints.geojson\")\n",
    "#dest_po[\"id\"] = range(len(da_centroids)+ 1, len(da_centroids) + len(dest_po) + 1) #adding id column\n",
    "\n",
    "da_centroids = gpd.read_file(\"data/data_CA/da_centroids_with_locations.geojson\").rename(columns={\"dauid\":\"id\"}) #1675 rows\n",
    "daycares = gpd.read_file(\"data/data_CA/daycare_locations.geojson\") #368 (total: OD = 616400)\n",
    "#hospitals = gpd.read_file(\"data/data_CA/hospital_locations.geojson\") # 5 (OD = 8375)\n",
    "\n",
    "print(len(da_centroids))\n",
    "print(len(daycares))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import h3\n",
    "import datetime\n",
    "from r5py import TransportNetwork, TravelTimeMatrixComputer, TransportMode\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_dest_h3(orig, dest, h3_res=9, ring_size=3):\n",
    "    # h3_res = 7: ~5.2km^2; h3_res = 8: ~0.74km^2; h3_res = 9: ~0.11km^2\n",
    "    # A k-ring of size k around a central hexagon includes all hexagons that are within k steps from the center.\n",
    "    # When ring_size=1, the k-ring includes: (1) The central hexagon; (2) the six hexagons surrounding the central hex. (total of 7 hexs)\n",
    "    # ring_size=2 means we have about 19 hexs\n",
    "\n",
    "    # Ensure same CRS\n",
    "    orig = orig.to_crs(\"EPSG:4326\")\n",
    "    dest = dest.to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # Convert origins and destinations to H3 indexes\n",
    "    orig[\"h3_i\"] = orig.apply(lambda i: h3.geo_to_h3(i.geometry.y, i.geometry.x, h3_res), axis=1)\n",
    "    dest[\"h3_i\"] = dest.apply(lambda i: h3.geo_to_h3(i.geometry.y, i.geometry.x, h3_res), axis=1)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    orig_rings = orig.apply(lambda row: set(h3.k_ring(row[\"h3_i\"], ring_size)), axis=1)\n",
    "    \n",
    "    for idx, o_ring in orig_rings.items():\n",
    "        o = orig.loc[idx]\n",
    "        matches = dest[dest[\"h3_i\"].isin(o_ring)]\n",
    "\n",
    "        for _, d in matches.iterrows():\n",
    "            results.append({\n",
    "                \"origin_id\": o[\"id\"],\n",
    "                \"dest_id\": d[\"id\"],\n",
    "                \"o_geometry\": o.geometry,\n",
    "                \"d_geometry\": d.geometry})\n",
    "    \n",
    "    od_pairs = gpd.GeoDataFrame(results, geometry=\"o_geometry\", crs=orig.crs)\n",
    "    od_pairs[\"d_geometry\"] = gpd.GeoSeries(od_pairs[\"d_geometry\"], crs=orig.crs)\n",
    "\n",
    "    grouped_od_pairs = od_pairs.groupby(\"origin_id\").agg({\"o_geometry\": \"first\", \"dest_id\": lambda x: list(x), \"d_geometry\": lambda x: list(x)}).reset_index()\n",
    "    grouped_od_pairs = gpd.GeoDataFrame(grouped_od_pairs, geometry=\"o_geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "    return od_pairs, grouped_od_pairs\n",
    "\n",
    "def compute_tt(grouped_od_pairs, transport_network, departure_time, time_window, modes):\n",
    "    \"\"\"\n",
    "    Compute travel times for origin-destination pairs using r5py.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    # Iterate through each origin\n",
    "    for _, row in tqdm(grouped_od_pairs.iterrows(), total=len(grouped_od_pairs), desc=\"Processing origins\"):\n",
    "\n",
    "        # Create GeoDataFrame for the current origin\n",
    "        origin = gpd.GeoDataFrame({\"id\": [row.origin_id], \"geometry\": [row.o_geometry]}, crs=grouped_od_pairs.crs)\n",
    "        \n",
    "        # Create GeoDataFrame for all destinations for this origin\n",
    "        destinations = gpd.GeoDataFrame({\"id\": row.dest_id, \"geometry\": row.d_geometry}, crs=grouped_od_pairs.crs)\n",
    "\n",
    "        travel_time_computer = TravelTimeMatrixComputer(\n",
    "                transport_network,\n",
    "                origins=origin,\n",
    "                destinations=destinations,\n",
    "                departure=departure_time,\n",
    "                departure_time_window=time_window,\n",
    "                transport_modes=modes)\n",
    "\n",
    "        travel_times = travel_time_computer.compute_travel_times()\n",
    "\n",
    "        # Aggregate results for each origin (taking min)\n",
    "        # if not travel_times.empty:\n",
    "        #     min_index = travel_times[\"travel_time\"].idxmin()\n",
    "        #     min_travel_time = travel_times.loc[min_index, \"travel_time\"]\n",
    "        #     min_dest_id = travel_times.loc[min_index, \"to_id\"]\n",
    "        #     min_dest_geometry = destinations.loc[destinations[\"id\"] == min_dest_id, \"geometry\"].iloc[0]\n",
    "\n",
    "        # all_results.append({\"origin_id\": row.origin_id,\"o_geometry\": row.o_geometry,\"min_travel_time\": min_travel_time,\n",
    "        #                 \"min_dest_id\": min_dest_id, \"d_geometry\": min_dest_geometry})\n",
    "        all_results.append(travel_times)\n",
    "           \n",
    "    return pd.concat(all_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OD pairs: 6639\n",
      "     origin_id                   o_geometry                   dest_id  \\\n",
      "0     48060056  POINT (-114.09749 51.13788)   [38, 42, 188, 214, 290]   \n",
      "1     48060057  POINT (-114.09353 51.13976)   [38, 42, 188, 214, 290]   \n",
      "2     48060058  POINT (-114.09522 51.13583)   [38, 42, 188, 214, 290]   \n",
      "3     48060059  POINT (-114.09047 51.13885)   [38, 42, 188, 214, 290]   \n",
      "4     48060060  POINT (-114.08807 51.13915)   [38, 42, 188, 214, 290]   \n",
      "...        ...                          ...                       ...   \n",
      "1538  48062787  POINT (-114.13346 51.07331)  [88, 108, 237, 251, 339]   \n",
      "1539  48062789  POINT (-114.04997 51.11896)           [126, 145, 154]   \n",
      "1540  48062790  POINT (-114.06178 51.12943)                [126, 145]   \n",
      "1541  48062791  POINT (-114.16624 51.04638)        [5, 297, 313, 324]   \n",
      "1542  48062792     POINT (-114.16901 51.04)        [5, 297, 313, 324]   \n",
      "\n",
      "                                             d_geometry  \n",
      "0     [POINT (-114.098894 51.1334222), POINT (-114.0...  \n",
      "1     [POINT (-114.098894 51.1334222), POINT (-114.0...  \n",
      "2     [POINT (-114.098894 51.1334222), POINT (-114.0...  \n",
      "3     [POINT (-114.098894 51.1334222), POINT (-114.0...  \n",
      "4     [POINT (-114.098894 51.1334222), POINT (-114.0...  \n",
      "...                                                 ...  \n",
      "1538  [POINT (-114.145682 51.0776122), POINT (-114.1...  \n",
      "1539  [POINT (-114.0535603 51.1244425), POINT (-114....  \n",
      "1540  [POINT (-114.0535603 51.1244425), POINT (-114....  \n",
      "1541  [POINT (-114.180056395548 51.04729805), POINT ...  \n",
      "1542  [POINT (-114.180056395548 51.04729805), POINT ...  \n",
      "\n",
      "[1543 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing origins: 100%|██████████| 1543/1543 [03:51<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 42s\n",
      "Wall time: 4min 23s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>to_id</th>\n",
       "      <th>travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48060056</td>\n",
       "      <td>38</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48060056</td>\n",
       "      <td>42</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48060056</td>\n",
       "      <td>188</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48060056</td>\n",
       "      <td>214</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48060056</td>\n",
       "      <td>290</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6634</th>\n",
       "      <td>48062791</td>\n",
       "      <td>324</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>48062792</td>\n",
       "      <td>5</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>48062792</td>\n",
       "      <td>297</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>48062792</td>\n",
       "      <td>313</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638</th>\n",
       "      <td>48062792</td>\n",
       "      <td>324</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6639 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       from_id  to_id  travel_time\n",
       "0     48060056     38         11.0\n",
       "1     48060056     42         24.0\n",
       "2     48060056    188         22.0\n",
       "3     48060056    214         25.0\n",
       "4     48060056    290         16.0\n",
       "...        ...    ...          ...\n",
       "6634  48062791    324         24.0\n",
       "6635  48062792      5         26.0\n",
       "6636  48062792    297         26.0\n",
       "6637  48062792    313         29.0\n",
       "6638  48062792    324         12.0\n",
       "\n",
       "[6639 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "od_pairs, grouped_od_pairs = find_dest_h3(da_centroids, daycares, h3_res=8, ring_size=1)\n",
    "print(f\"Number of OD pairs: {len(od_pairs)}\")\n",
    "\n",
    "print(grouped_od_pairs)\n",
    "\n",
    "#r5py\n",
    "network = TransportNetwork(\"data/data_CA/Calgary.osm.pbf\", [\"data/data_CA/cgy-gtfs-2023-03-03.zip\"])\n",
    "departure_time = datetime.datetime(2023, 3, 15, 7, 0)\n",
    "time_window = datetime.timedelta(hours=2)\n",
    "modes = [TransportMode.TRANSIT, TransportMode.WALK]\n",
    "\n",
    "#Compute Travel Time\n",
    "travel_times_df = compute_tt(grouped_od_pairs, network, departure_time, time_window, modes)\n",
    "travel_times_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_times_df.to_csv(\"H3_cal.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Your Transport Network\n",
    "\n",
    "To calculate travel times, we need to set up a transport network (which happens to be called a `TransportNetwork` class). The transport network needs both an underlying OpenStreetMap PBF file as well as one or more GTFS feeds. So let's go ahead and set up our transport network, which takes as its first argument the path to our PBF file and as a second argument a list of paths to GTFS files (of which we only have one in Calgary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not delete C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\2\\r5pylrv4op00\\TransportNetwork_1521f9e0890_00322f9\\Calgary.osm.pbf.mapdb.p, keeping in [WindowsPath('C:/Users/ADMINI~1/AppData/Local/Temp/2/r5pylrv4op00/TransportNetwork_1521f9e0890_00322f9/Calgary.osm.pbf.mapdb'), WindowsPath('C:/Users/ADMINI~1/AppData/Local/Temp/2/r5pylrv4op00/TransportNetwork_1521f9e0890_00322f9/Calgary.osm.pbf.mapdb.p'), WindowsPath('C:/Users/ADMINI~1/AppData/Local/Temp/2/r5pylrv4op00/TransportNetwork_1521f9e0890_00322f9/cgy-gtfs-2023-03-03.zip')]\n"
     ]
    }
   ],
   "source": [
    "from r5py import TransportNetwork\n",
    "\n",
    "# transport_network = TransportNetwork(\n",
    "#      \"data/mi-transporte-osm-crop.osm.pbf\",\n",
    "#      [\"data/improved-gtfs-mi-transporte.zip\"]\n",
    "#  )\n",
    "\n",
    "transport_network = TransportNetwork(\n",
    "    \"data/data_CA/Calgary.osm.pbf\",\n",
    "    [\"data/data_CA/cgy-gtfs-2023-03-03.zip\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will build us a transport network which we can use to compute travel times. So let's go ahead and do that next!\n",
    "## Computing Travel Times\n",
    "\n",
    "We create a travel time matrix computer (`TravelTimeMatrixComputer`) which lets us specify a whole bunch of potential parameters, most importantly origins and destinations. Our origins are the DA centroids, and our (first) destination will be the hospital centroids.\n",
    "\n",
    "**Note:** *The current version of r5py requires that we use the `TransitMode` and `LegMode` objects to specify our modes of travel. Future versions will allow us to just pass along strings like `\"WALK\"` or `\"TRANSIT\"`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 13s\n",
      "Wall time: 4min 8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>to_id</th>\n",
       "      <th>travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48060056</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48060056</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48060056</td>\n",
       "      <td>2</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48060056</td>\n",
       "      <td>3</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48060056</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616395</th>\n",
       "      <td>48062794</td>\n",
       "      <td>363</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616396</th>\n",
       "      <td>48062794</td>\n",
       "      <td>364</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616397</th>\n",
       "      <td>48062794</td>\n",
       "      <td>365</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616398</th>\n",
       "      <td>48062794</td>\n",
       "      <td>366</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616399</th>\n",
       "      <td>48062794</td>\n",
       "      <td>367</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         from_id  to_id  travel_time\n",
       "0       48060056      0        110.0\n",
       "1       48060056      1        101.0\n",
       "2       48060056      2        118.0\n",
       "3       48060056      3         89.0\n",
       "4       48060056      4         80.0\n",
       "...          ...    ...          ...\n",
       "616395  48062794    363          NaN\n",
       "616396  48062794    364        118.0\n",
       "616397  48062794    365        112.0\n",
       "616398  48062794    366         77.0\n",
       "616399  48062794    367          NaN\n",
       "\n",
       "[616400 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "from r5py import TravelTimeMatrixComputer, TransportMode\n",
    "\n",
    "#travel_time_computer = TravelTimeMatrixComputer(\n",
    "#    transport_network,\n",
    "#    origins=da_centroids,\n",
    "#    destinations=dest_po,\n",
    "#    departure=datetime.datetime(2021, 1, 1, 7, 0),\n",
    "#    departure_time_window=datetime.timedelta(minutes=10),\n",
    "#    max_time=datetime.timedelta(minutes=30),\n",
    "#    transport_modes=[TransportMode.TRANSIT, TransportMode.WALK]\n",
    "#)\n",
    "\n",
    "travel_time_computer = TravelTimeMatrixComputer(\n",
    "   transport_network,\n",
    "   origins=da_centroids,\n",
    "   destinations=daycares,\n",
    "   departure=datetime.datetime(2023, 3, 15, 7, 0),\n",
    "   departure_time_window=datetime.timedelta(hours=2),\n",
    "   transport_modes=[TransportMode.TRANSIT, TransportMode.WALK]\n",
    ")\n",
    "\n",
    "travel_time_computer.compute_travel_times()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Travel Times\n",
    "Now we're ready to run our computation. This will take a little while to run, and we'll write the matrix directly to a file. In order to avoid writing over the redundant datasets, lets write it to a new file `mx_hospitals_am_workshop.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODULAR VERSION\n",
    "from r5py import TravelTimeMatrixComputer, TransportMode\n",
    "import os\n",
    "import dill\n",
    "import numpy as np\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "#import pickle\n",
    "from functools import partial\n",
    "\n",
    "def load_or_create_dataframe(csv_file_path):\n",
    "    \"\"\"\n",
    "    Load the CSV file if it exists, otherwise create an empty DataFrame.\n",
    "    \"\"\"\n",
    "    if os.path.exists(csv_file_path):\n",
    "        return pd.read_csv(csv_file_path)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def calculate_num_batches(geodataframe, batch_size):\n",
    "    \"\"\"\n",
    "    Calculate the number of batches based on the size of the geodataframe.\n",
    "    \"\"\"\n",
    "    return math.ceil(len(geodataframe) / batch_size)\n",
    "\n",
    "def process_batch(args):\n",
    "    c_gdf1, c_gdf2 = args\n",
    "\n",
    "    # transport_network = TransportNetwork(\n",
    "    #     \"data/data_CA/Calgary.osm.pbf\",\n",
    "    #     [\"data/data_CA/cgy-gtfs-2023-03-03.zip\"])\n",
    "    travel_time_computer_c = TravelTimeMatrixComputer(\n",
    "                transport_network,\n",
    "                origins=c_gdf1,\n",
    "                destinations=c_gdf2,\n",
    "                departure=datetime.datetime(2023, 3, 15, 7, 0),\n",
    "                departure_time_window=datetime.timedelta(hours=2),\n",
    "                transport_modes= [TransportMode.TRANSIT, TransportMode.WALK])\n",
    "    return travel_time_computer_c.compute_travel_times()\n",
    "\n",
    "def process_batches(origin, destinations, BS_O, BS_D, csv_file_path):\n",
    "    \"\"\"\n",
    "    Process the data in batches and append results to a CSV file.\n",
    "    \"\"\"\n",
    "    # Load or create the DataFrame\n",
    "    travel_times_df = load_or_create_dataframe(csv_file_path)\n",
    "    \n",
    "    # Calculate the number of batches\n",
    "    num_b_o = calculate_num_batches(origin, BS_O)\n",
    "    num_b_d = calculate_num_batches(destinations, BS_D)\n",
    "\n",
    "    # Using multiprocessing\n",
    "    pool = mp.Pool(processes=4)\n",
    "    batch_args = []\n",
    "\n",
    "    # Perform the computation for the first geodataframe in batches\n",
    "    for i in range(num_b_o):\n",
    "        start_idx_gdf1 = i * BS_O\n",
    "        end_idx_gdf1 = min(start_idx_gdf1 + BS_O, len(origin))\n",
    "        chunk_gdf1 = origin.iloc[start_idx_gdf1:end_idx_gdf1]\n",
    "\n",
    "        # Perform the computation for the second geodataframe in batches\n",
    "        for j in range(num_b_d):\n",
    "            start_idx_gdf2 = j * BS_D\n",
    "            end_idx_gdf2 = min(start_idx_gdf2 + BS_D, len(destinations))\n",
    "            chunk_gdf2 = destinations.iloc[start_idx_gdf2:end_idx_gdf2]\n",
    "\n",
    "            batch_args.append((chunk_gdf1, chunk_gdf2))\n",
    "\n",
    "    results = pool.map(process_batch, batch_args)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # for result in results:\n",
    "    #     result.to_csv(csv_file_path, mode='a', header=not os.path.exists(csv_file_path), index=False)\n",
    "\n",
    "    #travel_times_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_network = TransportNetwork(\n",
    "    \"data/data_CA/Calgary.osm.pbf\",\n",
    "    [\"data/data_CA/cgy-gtfs-2023-03-03.zip\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the batch size for processing\n",
    "BS_O = 1000  # Adjust as needed - origin\n",
    "BS_D = 1000     # Adjust as needed - destination\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file_path = 'data/full_matrix.csv'\n",
    "\n",
    "# transport_network = TransportNetwork(\n",
    "#     \"data/data_CA/Calgary.osm.pbf\",\n",
    "#     [\"data/data_CA/cgy-gtfs-2023-03-03.zip\"])\n",
    "\n",
    "# Process batches and get the final DataFrame\n",
    "final_travel_times_df = process_batches(da_centroids, daycares, BS_O, BS_D, csv_file_path)\n",
    "\n",
    "print(\"FIN!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 6)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_last_processed_batch():\n",
    "    try:\n",
    "        with open('data/guadalajara/last_processed_batch.pkl', 'rb') as f:\n",
    "            return dill.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "last_processed_batch = load_last_processed_batch()\n",
    "last_processed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000001AA18288520>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\heinl\\anaconda3\\envs\\ghn\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 785, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "  File \"C:\\Users\\heinl\\anaconda3\\envs\\ghn\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 785, in <setcomp>\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "  File \"C:\\Users\\heinl\\anaconda3\\envs\\ghn\\lib\\threading.py\", line 1154, in ident\n",
      "    assert self._initialized, \"Thread.__init__() not called\"\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('data/guadalajara/travel_times_walking.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    dill.dump(list(reader), open('data/guadalajara/guadalajara.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r5py-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
